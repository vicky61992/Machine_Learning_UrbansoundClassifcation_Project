{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import IPython as IP\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pickle\n",
    "import helpers\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import clear_output, display\n",
    "from scipy.stats import kurtosis, skew\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Meta_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8732, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>100032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.500000</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100263-2-0-143.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>71.500000</td>\n",
       "      <td>75.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100263-2-0-161.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>80.500000</td>\n",
       "      <td>84.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100263-2-0-3.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100263-2-0-36.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100648-1-0-0.wav</td>\n",
       "      <td>100648</td>\n",
       "      <td>4.823402</td>\n",
       "      <td>5.471927</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      slice_file_name    fsID      start        end  salience  fold  classID  \\\n",
       "0    100032-3-0-0.wav  100032   0.000000   0.317551         1     5        3   \n",
       "1  100263-2-0-117.wav  100263  58.500000  62.500000         1     5        2   \n",
       "2  100263-2-0-121.wav  100263  60.500000  64.500000         1     5        2   \n",
       "3  100263-2-0-126.wav  100263  63.000000  67.000000         1     5        2   \n",
       "4  100263-2-0-137.wav  100263  68.500000  72.500000         1     5        2   \n",
       "5  100263-2-0-143.wav  100263  71.500000  75.500000         1     5        2   \n",
       "6  100263-2-0-161.wav  100263  80.500000  84.500000         1     5        2   \n",
       "7    100263-2-0-3.wav  100263   1.500000   5.500000         1     5        2   \n",
       "8   100263-2-0-36.wav  100263  18.000000  22.000000         1     5        2   \n",
       "9    100648-1-0-0.wav  100648   4.823402   5.471927         2    10        1   \n",
       "\n",
       "              class  \n",
       "0          dog_bark  \n",
       "1  children_playing  \n",
       "2  children_playing  \n",
       "3  children_playing  \n",
       "4  children_playing  \n",
       "5  children_playing  \n",
       "6  children_playing  \n",
       "7  children_playing  \n",
       "8  children_playing  \n",
       "9          car_horn  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set your path to the dataset\n",
    "# Load the metadata from the generated CSV\n",
    "meta_data=pd.read_csv('C:/Users/VSBAG/Desktop/DSE_Milan/3rd_sem_subject/Machine Learning/Project/Sound_classification/UrbanSound8K/metadata/UrbanSound8K.csv')\n",
    "audio_dataset_path='C:/Users/VSBAG/Desktop/DSE_Milan/3rd_sem_subject/Machine Learning/Project/Sound_classification/UrbanSound8K/audio/'\n",
    "print(meta_data.shape)\n",
    "meta_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method of  MFCC coefficients extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 501/8732\n",
      "Status: 1001/8732\n",
      "Status: 1501/8732\n",
      "Status: 2001/8732\n",
      "Status: 2501/8732\n",
      "Status: 3001/8732\n",
      "Status: 3501/8732\n",
      "Status: 4001/8732\n",
      "Status: 4501/8732\n",
      "Status: 5001/8732\n",
      "Status: 5501/8732\n",
      "Status: 6001/8732\n",
      "Status: 6501/8732\n",
      "Status: 7001/8732\n",
      "Status: 7501/8732\n",
      "Status: 8001/8732\n",
      "Status: 8501/8732\n",
      "Finished: 8731/8732\n"
     ]
    }
   ],
   "source": [
    "# Iterate through all audio files and extract MFCC\n",
    "features = []\n",
    "labels = []\n",
    "frames_max = 0\n",
    "counter = 0\n",
    "total_samples = len(meta_data)\n",
    "n_mfcc = 40\n",
    "\n",
    "for index, row in meta_data.iterrows():\n",
    "    file_path = os.path.join(os.path.abspath(audio_path), 'fold' + str(row[\"fold\"]), str(row[\"slice_file_name\"]))\n",
    "    class_label = row[\"class\"]\n",
    "\n",
    "    # Extract MFCCs (do not add padding)\n",
    "    mfccs = helpers.get_mfcc(file_path, 0, n_mfcc)\n",
    "    \n",
    "    # Save current frame count\n",
    "    num_frames = mfccs.shape[1]\n",
    "    \n",
    "    # Add row (feature / label)\n",
    "    features.append(mfccs)\n",
    "    labels.append(class_label)\n",
    "\n",
    "    # Update frames maximum\n",
    "    if (num_frames > frames_max):\n",
    "        frames_max = num_frames\n",
    "\n",
    "    # Notify update every N files\n",
    "    if (counter == 500):\n",
    "        print(\"Status: {}/{}\".format(index+1, total_samples))\n",
    "        counter = 0\n",
    "\n",
    "    counter += 1\n",
    "    \n",
    "print(\"Finished: {}/{}\".format(index, total_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = []\n",
    "\n",
    "# Add padding\n",
    "mels_max_padding = frames_max\n",
    "for i in range(len(features)):\n",
    "    size = len(features[i][0])\n",
    "    if (size < mels_max_padding):\n",
    "        pad_width = mels_max_padding - size\n",
    "        px = np.pad(features[i], \n",
    "                    pad_width=((0, 0), (0, pad_width)), \n",
    "                    mode='constant', \n",
    "                    constant_values=(0,))\n",
    "    \n",
    "    padded.append(px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add padding to features with less than frames than frames_max\n",
    "padded_features = helpers.add_padding(features, frames_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save MFCC features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features (X) and labels (y) to Numpy arrays\n",
    "X = np.array(padded)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Optionally save the features to disk\n",
    "np.save(\"C:/Users/VSBAG/Desktop/DSE_Milan/3rd_sem_subject/Machine Learning/Project/Sound_classification/UrbanSound8K/extracted_features/X-mfcc\", X)\n",
    "np.save(\"C:/Users/VSBAG/Desktop/DSE_Milan/3rd_sem_subject/Machine Learning/Project/Sound_classification/UrbanSound8K/extracted_features/y-mfcc\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction : Mel Spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 501/8732\n",
      "Status: 1001/8732\n",
      "Status: 1501/8732\n",
      "Status: 2001/8732\n",
      "Status: 2501/8732\n",
      "Status: 3001/8732\n",
      "Status: 3501/8732\n",
      "Status: 4001/8732\n",
      "Status: 4501/8732\n",
      "Status: 5001/8732\n",
      "Status: 5501/8732\n",
      "Status: 6001/8732\n",
      "Status: 6501/8732\n",
      "Status: 7001/8732\n",
      "Status: 7501/8732\n",
      "Status: 8001/8732\n",
      "Status: 8501/8732\n",
      "Finished: 8731/8732\n"
     ]
    }
   ],
   "source": [
    "# Iterate through all audio files and extract mel spectogram\n",
    "features = []\n",
    "labels = []\n",
    "frames_max = 0\n",
    "counter = 0\n",
    "total_samples = len(meta_data)\n",
    "n_mels=40\n",
    "\n",
    "for index, row in meta_data.iterrows():\n",
    "    file_path = os.path.join(os.path.abspath(audio_dataset_path), 'fold' + str(row[\"fold\"]), str(row[\"slice_file_name\"]))\n",
    "    class_label = row[\"class\"]\n",
    "\n",
    "    # Extract Log-Mel Spectrograms (do not add padding)\n",
    "    mels = helpers.get_mel_spectrogram(file_path, 0, n_mels=n_mels)\n",
    "    \n",
    "    # Save current frame count\n",
    "    num_frames = mels.shape[1]\n",
    "    \n",
    "    # Add row (feature / label)\n",
    "    features.append(mels)\n",
    "    labels.append(class_label)\n",
    "\n",
    "    # Update frames maximum\n",
    "    if (num_frames > frames_max):\n",
    "        frames_max = num_frames\n",
    "\n",
    "    # Notify update every N files\n",
    "    if (counter == 500):\n",
    "        print(\"Status: {}/{}\".format(index+1, total_samples))\n",
    "        counter = 0\n",
    "\n",
    "    counter += 1\n",
    "    \n",
    "print(\"Finished: {}/{}\".format(index, total_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = []\n",
    "\n",
    "# Add padding\n",
    "mels_max_padding = frames_max\n",
    "for i in range(len(features)):\n",
    "    size = len(features[i][0])\n",
    "    if (size < mels_max_padding):\n",
    "        pad_width = mels_max_padding - size\n",
    "        px = np.pad(features[i], \n",
    "                    pad_width=((0, 0), (0, pad_width)), \n",
    "                    mode='constant', \n",
    "                    constant_values=(0,))\n",
    "    \n",
    "    padded.append(px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add padding to features with less than frames than frames_max\n",
    "padded_features = helpers.add_padding(features, frames_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert features (X) and labels (y) to Numpy arrays\n",
    "\n",
    "X = np.array(padded)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Optionally save the features to disk\n",
    "np.save(\"C:/Users/VSBAG/Desktop/DSE_Milan/3rd_sem_subject/Machine Learning/Project/Sound_classification/UrbanSound8K/extracted_features/X-mel_spec-augmented\", X)\n",
    "np.save(\"C:/Users/VSBAG/Desktop/DSE_Milan/3rd_sem_subject/Machine Learning/Project/Sound_classification/UrbanSound8K/extracted_features/y-mel_spec-augmented\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction : Chromagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: 8731/8732\n"
     ]
    }
   ],
   "source": [
    "# Iterate through all audio files and extract chromagram\n",
    "features = []\n",
    "labels = []\n",
    "frames_max = 0\n",
    "counter = 0\n",
    "total_samples = len(meta_data)\n",
    "n_chroma = 40\n",
    "\n",
    "\n",
    "#Iterating through all audio files and extracting chromagram\n",
    "for index, row in meta_data.iterrows():\n",
    "    file_path = os.path.join(os.path.abspath('UrbanSound8K/audio'), 'fold' + str(row[\"fold\"]), str(row[\"slice_file_name\"]))\n",
    "    class_label = row[\"class\"]\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path)\n",
    "        normalized_y = librosa.util.normalize(y)\n",
    "        chromagram = librosa.feature.chroma_stft(y=normalized_y,\n",
    "                                        sr=sr)\n",
    "        \n",
    "        normalized_chroma = librosa.util.normalize(chromagram)\n",
    "        shape = normalized_chroma.shape[1]\n",
    "        chroma = normalized_chroma\n",
    "        num_frames = chroma.shape[1]\n",
    "        features.append(chroma)\n",
    "        labels.append(class_label)\n",
    "        if (num_frames > frames_max):\n",
    "            frames_max = num_frames\n",
    "        if (counter == 1):\n",
    "            print(\"Status: {}/{}\".format(index+1, total_samples))\n",
    "            counter = 0\n",
    "        counter += 1\n",
    "    except Exception:\n",
    "        pass\n",
    "print(\"Finished: {}/{}\".format(index, total_samples))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding the feature variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given an numpy array of features, zero-pads each ocurrence to max_padding\n",
    "def add_padding(features, chroma_max_padding=174):\n",
    "    padded = []\n",
    "    for i in range(len(features)):\n",
    "        px = features[i]\n",
    "        size = len(px[0])\n",
    "        # Add padding if required\n",
    "        if (size < chroma_max_padding):\n",
    "            xDiff = chroma_max_padding - size\n",
    "            xLeft = xDiff//2\n",
    "            xRight = xDiff-xLeft\n",
    "            px = np.pad(px, pad_width=((0,0), (xLeft, xRight)), mode='constant')\n",
    "        \n",
    "        padded.append(px)\n",
    "\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add padding to features with less than frames than frames_max\n",
    "padded_features = add_padding(features, frames_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features (X) and labels (y) to Numpy arrays\n",
    "\n",
    "X = np.array(padded) #Padded Feature are converted to numpy array & stored in X\n",
    "y = np.array(labels) #Labels are coverted to numpy array & stored in y\n",
    "\n",
    "# Optionally save the features to disk\n",
    "np.save(\"C:/Users/VSBAG/Desktop/DSE_Milan/3rd_sem_subject/Machine Learning/Project/Sound_classification/UrbanSound8K/extracted_features/X-Chromo\", X)\n",
    "np.save(\"C:/Users/VSBAG/Desktop/DSE_Milan/3rd_sem_subject/Machine Learning/Project/Sound_classification/UrbanSound8K/extracted_features/y-Chromo\", y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
